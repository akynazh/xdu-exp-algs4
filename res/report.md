# 算法分析与设计实验报告

## 实验一：渗透问题

### 题目描述

使用合并-查找（union-find）数据结构，编写程序通过蒙特卡罗模拟（Monte Carlo simulation）来估计渗透阈值的值。

### 解决方法

随机open格点，每open一个格点，和该格点周围的已经open的格点并入同一个集合，即，它们有了相同的“祖先”。相关代码如下：

```java
// 打开一个格点，并检查相邻4个方向，看是否能合并
public void open(int i, int j) {
    validate(i, j);
    grid.open(getIdx(i, j));
    int[] dx = {-1, 0, 0, 1}, dy = {0, 1, -1, 0};
    for (int k = 0; k < 4; k++) {
        try {
            int m = i + dx[k], n = j + dy[k];
            validate(m, n);
            if (grid.isOpen(getIdx(m, n)) && !grid.connected(getIdx(m, n), getIdx(i, j))) {
                grid.union(getIdx(m, n), getIdx(i, j));
            }
        } catch (Exception ignored) {
        }
    }
}
```

当open的格点大于等于N个，系统有可能开始发生渗透，此时每open一个格点，需要开始判断系统是否渗透，判断方法是：判断最底层的任一格点是否和最顶层的任一格点处在同一个集合中，如果是，那么可以退出必然有一条从最顶层到最底层的通路，即，发生了渗透。相关代码如下：

```java
// 如果当前格点和最顶层的任一格点处在同一集合中则full了
public boolean isFull(int i, int j) {
    validate(i, j);
    for (int k = 1; k <= N; k++) {
        if (grid.connected(getIdx(i, j), getIdx(1, k))) return true;
    }
    return false;
}

// 如果最底层格点和最顶层的任一格点处在同一集合中则percolates了
public boolean percolates() {
    if (grid.getCurrentCount() > N * (N - 1)) return false;
    for (int i = 1; i <= N; i++) {
        if (isOpen(N, i) && isFull(N, i)) return true;
    }
    return false;
}
```

通过两种方法进行合并查找算法，不带权值的合并查找和带权值的合并查找算法。自己实现的合并查找算法主要代码如下：

查找部分：

通过递归的方法，寻找祖先并逐步合并。

```java
// 寻找祖先并逐步合并
public int findParent(int p) {
    if (parent[p] != p) {
        return parent[p] = findParent(parent[p]);
    }
    return p;
}
```

合并部分：(带权值的和不带权值的)

带权值的合并：

```java
// 合并2个格点
public void union(int p, int q) {
    int rootP = findParent(p);
    int rootQ = findParent(q);
    if (rootP == rootQ) return;
    parent[rootP] = rootQ;
    currentCount--;
}
```

不带权值的合并：

```java
public void union(int p, int q) {
    int rootP = findParent(p);
    int rootQ = findParent(q);
    if (rootP == rootQ) return;

    if (weight[rootP] < weight[rootQ]) {
        parent[rootP] = rootQ;
        weight[rootQ] += weight[rootP];
    } else {
        parent[rootQ] = rootP;
        weight[rootP] += weight[rootQ];
    }
    currentCount--;
}
```

为了比较算法效率差异，在T=100，即每次实验次数为100下，通过逐步增大N值，计算不同N值情况下的平均运行时间，空置概率平均值，方差和置信区间。

### 实验结果与分析

实验结果如下：

```
########## N = 10, T = 100 时 ##########
-------------------------------------------
QuickFindUF算法：
-------------------------------------------
average use time: 0.000220s
mean: 0.6794000000000001
stddev: 0.1599293333333333
confidence: [0.6480538506666668, 0.7107461493333335]
-------------------------------------------

WeightedQuickFindUF算法：
-------------------------------------------
average use time: 0.000180s
mean: 0.6125000000000000
stddev: 0.3487944444444440
confidence: [0.5441362888888890, 0.6808637111111111]
-------------------------------------------

########## N = 50, T = 100 时 ##########
-------------------------------------------
QuickFindUF算法：
-------------------------------------------
average use time: 0.001820s
mean: 0.6255839999999999
stddev: 0.0056200158040816
confidence: [0.6244824769023999, 0.6266855230976000]
-------------------------------------------

WeightedQuickFindUF算法：
-------------------------------------------
average use time: 0.001725s
mean: 0.6066239999999997
stddev: 0.0094927911183674
confidence: [0.6047634129407997, 0.6084845870591997]
-------------------------------------------

########## N = 100, T = 100 时 ##########
-------------------------------------------
QuickFindUF算法：
-------------------------------------------
average use time: 0.018320s
mean: 0.6105490000000000
stddev: 0.0014421334333333
confidence: [0.6102663418470666, 0.6108316581529334]
-------------------------------------------

WeightedQuickFindUF算法：
-------------------------------------------
average use time: 0.015610s
mean: 0.5941875000000002
stddev: 0.0024944444318182
confidence: [0.5936985888913638, 0.5946764111086366]
-------------------------------------------
```

可以明显发现，带权值的合并查找算法比不带权值的合并算法所花时间小，当数据规模越来越大，差距进一步加大。

同时，随着N值的增大，对于空置概率p：

平均值：逐渐减小，带权值的合并查找算法都小于不带权值的合并查找算法；

方差：逐渐减小，带权值的合并查找算法都大于不带权值的合并查找算法；

置信区间：逐渐缩小，带权值的合并查找算法都小于不带权值的合并查找算法。

## 实验二：几种排序算法的实验性能比较

### 题目描述

实现插入排序（Insertion Sort，IS），自顶向下归并排序（Top-down Mergesort，TDM），自底向上归并排序（Bottom-up Mergesort，BUM），随机快速排序（Random Quicksort，RQ），Dijkstra 3-路划分快速排序（Quicksort with Dijkstra 3-way Partition，QD3P）。

在你的计算机上针对不同输入规模数据进行实验，对比上述排序算法的时间性能。要求对于每次输入运行10次，记录每次时间，取平均值。

### 解决方法

插入排序：从前往后开始遍历，将后面的元素插到前面已经排序好的元素中去。

```java
public static void sort(int[] arr) {
    if (arr.length == 0 || arr.length == 1) return;
    for (int i = 1; i < arr.length; i++) {
        int num = arr[i], j = i - 1;
        while (j >= 0 && arr[j] > num)
            j--;
        for (int k = i; k > j + 1; k--)
            arr[k] = arr[k - 1];
        arr[j + 1] = num;
    }
}
```

自顶向下归并排序：从顶（整体）向下（局部）进行归并，递归地进行，每次归并时左右都是已排序的元素。

```java
public static void mergeSort(int[] arr, int lo, int hi) {
    if (hi <= lo) return;
    int mid = (lo + hi) / 2;
    mergeSort(arr, lo, mid);
    mergeSort(arr, mid + 1, hi);
    merge(arr, lo, mid, hi);
}
public static void merge(int[] arr, int lo, int mid, int hi) {
    int[] tmp = new int[hi - lo + 1];
    int cur = mid + 1, o_lo = lo;
    for (int i = 0; i < tmp.length; i++) {
        if (lo > mid && cur <= hi) tmp[i] = arr[cur++];
        else if (cur > hi && lo <= mid) tmp[i] = arr[lo++];
        else {
            if (arr[lo] <= arr[cur]) tmp[i] = arr[lo++];
            else tmp[i] = arr[cur++];
        }
    }
    for (int val : tmp) arr[o_lo++] = val;
}
```

自底向上归并排序：自底（局部）向上（整体）地进行归并，以块为单位进行归并，逐步最大块中元素个数，直到块个数为总个数一半为止。

注：归并的方法和自顶向下的归并排序一样，可以直接引用 TopDownMergeSort.merge 方法。

```java
public static void sort(int[] arr) {
    int N = arr.length;
    for (int sz = 1; sz < N; sz = sz << 1) {
        for (int lo = 0; lo < N - sz; lo += sz << 1) {
            TopDownMergeSort.merge(arr, lo, lo + sz - 1, Math.min(lo + (sz << 1) - 1, N - 1));
        }
    }
}
```

随机快速排序：不断选取枢轴划分将数组划分为左右部分数组（左小右大，或反之），递归地进行。

由于测试时数组的输入即为任意的指定，所以无需再次打乱数组。

```java
public static void quickSort(int[] arr, int lo, int hi) {
    if (hi <= lo) return;
    int piv = partition(arr, lo, hi);
    quickSort(arr, lo, piv - 1);
    quickSort(arr, piv + 1, hi);
}

public static int partition(int[] arr, int lo, int hi) {
    int val = arr[lo], i = lo, j = hi;
    while (i < j) {
        while (i < j && arr[j] >= val) j--;
        arr[i] = arr[j];
        while (i < j && arr[i] <= val) i++;
        arr[j] = arr[i];
    }
    arr[i] = val;
    return i;
}
```

Dijkstra 3-路划分快速排序：相比于普通的快速排序，将与枢轴相等的元素也作为一个考虑元素，每次递归将数组划分为小于枢轴的，等于枢轴的，大于枢轴的三个部分。

```java
public static void quickSortWithD3P(int[] arr, int lo, int hi) {
    if (hi <= lo) return;
    int lt = lo, i = lo + 1, gt = hi, val = arr[lo];
    while (i <= gt) {
        if (arr[i] < val) Common.exch(arr, i++, lt++);
        else if (arr[i] > val) Common.exch(arr, i, gt--);
        else i++;
    }
    quickSortWithD3P(arr, lo, lt - 1);
    quickSortWithD3P(arr, gt + 1, hi);
}
```

### 实验结果与分析

```
-----------------------------------------
array size: 100
InsertionSort     ->      1ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      |     0ms
TopDownMergeSort  ->      1ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      |     0ms
BottomUpMergeSort ->      3ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      |     0ms
RandomQuickSort   ->      1ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      |     0ms
QuickSortWithD3P  ->      1ms      0ms      1ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      |     0ms
-----------------------------------------

-----------------------------------------
array size: 1000
InsertionSort     ->      2ms      1ms      1ms      1ms      1ms      2ms      0ms      0ms      0ms      0ms      |     0ms
TopDownMergeSort  ->      0ms      0ms      0ms      0ms      0ms      0ms      1ms      0ms      0ms      0ms      |     0ms
BottomUpMergeSort ->      0ms      1ms      0ms      0ms      0ms      0ms      1ms      0ms      0ms      0ms      |     0ms
RandomQuickSort   ->      0ms      1ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      |     0ms
QuickSortWithD3P  ->      0ms      2ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      |     0ms
-----------------------------------------

-----------------------------------------
array size: 10000
InsertionSort     ->     13ms     15ms     12ms     14ms     13ms     13ms     12ms     14ms     13ms     13ms      |    13ms
TopDownMergeSort  ->      1ms      0ms      1ms      1ms      1ms      1ms      1ms      1ms      1ms      1ms      |     0ms
BottomUpMergeSort ->      2ms      1ms      2ms      1ms      2ms      1ms      1ms      1ms      2ms      1ms      |     1ms
RandomQuickSort   ->      1ms      0ms      1ms      0ms      1ms      1ms      0ms      1ms      0ms      1ms      |     0ms
QuickSortWithD3P  ->      1ms      1ms      0ms      1ms      1ms      0ms      1ms      1ms      1ms      0ms      |     0ms
-----------------------------------------

-----------------------------------------
array size: 100000
InsertionSort     ->   1271ms   1222ms   1247ms   1255ms   1237ms   1222ms   1207ms   1234ms   1219ms   1236ms      |  1235ms
TopDownMergeSort  ->     13ms     17ms     16ms     16ms      8ms     10ms     10ms     10ms     10ms      9ms      |    11ms
BottomUpMergeSort ->     13ms     10ms     10ms     12ms     11ms     11ms     11ms     13ms     11ms     10ms      |    11ms
RandomQuickSort   ->      6ms      8ms      6ms      7ms      6ms      6ms      7ms      6ms      8ms      6ms      |     6ms
QuickSortWithD3P  ->      6ms      6ms      7ms      7ms      6ms      8ms      7ms      6ms      6ms      7ms      |     6ms
-----------------------------------------

-----------------------------------------
array size: 1000000
InsertionSort     ->  116852ms  118249ms  116646ms  116994ms  121737ms  120262ms  116222ms  117394ms  115078ms  116368ms      | 117580ms
TopDownMergeSort  ->    127ms    106ms    102ms    105ms    105ms    109ms    163ms    108ms    103ms    106ms      |   113ms
BottomUpMergeSort ->    118ms    115ms    122ms    119ms    121ms    121ms    120ms    119ms    121ms    118ms      |   119ms
RandomQuickSort   ->     86ms     80ms     82ms     82ms     84ms     84ms     81ms     83ms     81ms     82ms      |    82ms
QuickSortWithD3P  ->     61ms     63ms     61ms     64ms     65ms     63ms     63ms     63ms     62ms     64ms      |    62ms
-----------------------------------------
```

分析结果可知，当数据规模较小时，几个算法速度几乎没有差异，当数据规模逐渐增大，各个算法差异有了非常明显的差异：

快速排序和归并排序远远快于插入排序；

快速排序稍快于归并排序；

自顶向下和自底向上的插入排序差异不大，普通的快速排序和三路快速排序差异不大；

当数据规模为1000000，而我定义的随机数范围是0到10000，此时重复元素较多，发现三路快速排序比普通的快速排序要快一点。

### 问题回答

1. Which sort worked best on data in constant or increasing order (i.e., already sorted data)? Why do you think this sort worked best?

当数据成这种规律排列时，使用插入排序将会是最有效的，它以最简单的方式对元素进行排序，一轮遍历即可完成，不需要无意义地进行多次递归。

2. Did the same sort do well on the case of mostly sorted data? Why or why not?

当大多数元素已经排好序，使用插入排序未必是最高效的，因为它可能需要花大量时间在元素的移动上，这在数据规模很大的情况下将耗费大量时间，即使只有少部分元素需要插入。

3. In general, did the ordering of the incoming data affect the performance of the sorting algorithms? Please answer this question by referencing specific data from your table to support your answer.

会影响。当输入数组是已排序数组时，结果如下：

```
-----------------------------------------
array size: 10000
InsertionSort     ->      1ms      0ms      1ms      0ms      1ms      0ms      0ms      0ms      0ms      0ms      |     0ms
TopDownMergeSort  ->      1ms      1ms      1ms      1ms      0ms      2ms      0ms      1ms      1ms      0ms      |     0ms
BottomUpMergeSort ->      1ms      2ms      1ms      1ms      1ms      1ms      1ms      0ms      1ms      0ms      |     0ms
RandomQuickSort   ->     10ms      9ms     11ms      9ms     10ms     10ms     10ms     11ms      9ms     10ms      |     9ms
QuickSortWithD3P  ->      2ms      1ms      1ms      2ms      2ms      2ms      1ms      2ms      2ms      1ms      |     1ms
-----------------------------------------
```

可以发现插入排序是最快的，快速排序受到了影响，慢于插入排序。

4. Which sort did best on the shorter (i.e., n = 1,000) data sets? Did the same one do better on the longer (i.e., n = 10,000) data sets? Why or why not? Please use specific data from your table to support your answer.

分析结果可知，当数据规模较小时，几个算法速度几乎没有差异：

```
-----------------------------------------
array size: 1000
InsertionSort     ->      2ms      1ms      1ms      1ms      1ms      2ms      0ms      0ms      0ms      0ms      |     0ms
TopDownMergeSort  ->      0ms      0ms      0ms      0ms      0ms      0ms      1ms      0ms      0ms      0ms      |     0ms
BottomUpMergeSort ->      0ms      1ms      0ms      0ms      0ms      0ms      1ms      0ms      0ms      0ms      |     0ms
RandomQuickSort   ->      0ms      1ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      |     0ms
QuickSortWithD3P  ->      0ms      2ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      0ms      |     0ms
-----------------------------------------
```

当数据规模逐渐增大，各个算法差异有了非常明显的差异：

快速排序和归并排序远远快于插入排序；

快速排序稍快于归并排序；

自顶向下和自底向上的插入排序差异不大，普通的快速排序和三路快速排序差异不大；

当数据规模为1000000，而我定义的随机数范围是0到10000，此时重复元素较多，发现三路快速排序比普通的快速排序要快一点。

```
-----------------------------------------
array size: 100000
InsertionSort     ->   1271ms   1222ms   1247ms   1255ms   1237ms   1222ms   1207ms   1234ms   1219ms   1236ms      |  1235ms
TopDownMergeSort  ->     13ms     17ms     16ms     16ms      8ms     10ms     10ms     10ms     10ms      9ms      |    11ms
BottomUpMergeSort ->     13ms     10ms     10ms     12ms     11ms     11ms     11ms     13ms     11ms     10ms      |    11ms
RandomQuickSort   ->      6ms      8ms      6ms      7ms      6ms      6ms      7ms      6ms      8ms      6ms      |     6ms
QuickSortWithD3P  ->      6ms      6ms      7ms      7ms      6ms      8ms      7ms      6ms      6ms      7ms      |     6ms
-----------------------------------------

-----------------------------------------
array size: 1000000
InsertionSort     ->  116852ms  118249ms  116646ms  116994ms  121737ms  120262ms  116222ms  117394ms  115078ms  116368ms      | 117580ms
TopDownMergeSort  ->    127ms    106ms    102ms    105ms    105ms    109ms    163ms    108ms    103ms    106ms      |   113ms
BottomUpMergeSort ->    118ms    115ms    122ms    119ms    121ms    121ms    120ms    119ms    121ms    118ms      |   119ms
RandomQuickSort   ->     86ms     80ms     82ms     82ms     84ms     84ms     81ms     83ms     81ms     82ms      |    82ms
QuickSortWithD3P  ->     61ms     63ms     61ms     64ms     65ms     63ms     63ms     63ms     62ms     64ms      |    62ms
-----------------------------------------
```

5. In general, which sort did better? Give a hypothesis as to why the difference in performance exists.

总体而言，快速排序最快。

分析结果可知，当数据规模较小时，几个算法速度几乎没有差异，当数据规模逐渐增大，各个算法差异有了非常明显的差异：

快速排序和归并排序远远快于插入排序；

快速排序稍快于归并排序；

自顶向下和自底向上的插入排序差异不大，普通的快速排序和三路快速排序差异不大；

当数据规模为1000000，而我定义的随机数范围是0到10000，此时重复元素较多，发现三路快速排序比普通的快速排序要快一点。

6. Are there results in your table that seem to be inconsistent? (e.g., If I get run times for a sort that look like this {1.3, 1.5, 1.6, 7.0, 1.2, 1.6, 1.4, 1.8, 2.0, 1.5] the 7.0 entry is not consistent with the rest). Why do you think this happened?

有。这可以归因于多种情况，如CPU运行受限，数据排序较为特别（如大多已经排好或者倒序排列）。

## 实验三：地图路由（Map Routing）

### 题目描述

实现经典的Dijkstra最短路径算法，并对其进行优化。

这种算法广泛应用于地理信息系统（GIS），包括MapQuest和基于GPS的汽车导航系统。

本次实验对象是图maps或graphs，其中顶点为平面上的点，这些点由权值为欧氏距离的边相连成图。 

可将顶点视为城市，将边视为相连的道路。 

为了在文件中表示地图，我们列出了顶点数和边数，然后列出顶点（索引后跟其x和y坐标），然后列出边（顶点对），最后列出源点和汇点。

优化Dijkstra算法，使其可以处理给定图的数千条最短路径查询。 

一旦你读取图（并可选地预处理），你的程序应该在亚线性时间内解决最短路径问题。 

一种方法是预先计算出所有顶点对的最短路径；然而，你无法承受存储所有这些信息所需的二次空间。 

你的目标是减少每次最短路径计算所涉及的工作量，而不会占用过多的空间。

### 解决方法

采用A*算法优化迪杰斯特拉算法：

利用启发式搜索的思想，额外计算一个预期值来进行对搜索的控制，从而使得搜索搜索范围变得合理且速度更快。

关于A*算法：

该算法通过下面这个函数来计算每个节点的优先级。

```
f(n)=g(n)+h(n)
```

在上式中：

- f(n)为节点n的综合优先级； 
- g(n)为节点n距离起点的代价； 
- h(n)为节点n距离终点的预计代价。

上式即为A*算法的启发函数。A*算法在运算过程中，每次从优先队列中选取f(n)值最小（优先级最高）的节点作为下一个待遍历的节点。

另外，A*算法使用两个集合来表示待遍历的节点，与已经遍历过的节点，这通常称之为open_set和close_set。完整的A*算法描述如下：

```
* 初始化open_set和close_set；
* 将起点加入open_set中，并设置优先级为0（优先级最高）；
* 如果open_set不为空，则从open_set中选取优先级最高的节点n：
    * 如果节点n为终点，则：
        * 从终点开始逐步追踪parent节点，一直达到起点；
        * 返回找到的结果路径，算法结束；
    * 如果节点n不是终点，则：
        * 将节点n从open_set中删除，并加入close_set中；
        * 遍历节点n所有的邻近节点：
            * 如果邻近节点m在close_set中，则：
                * 跳过，选取下一个邻近节点
            * 如果邻近节点m也不在open_set中，则：
                * 设置节点m的parent为节点n
                * 计算节点m的优先级
                * 将节点m加入open_set中
                  上面已经提到，启发函数会影响A*算法的行为。
```

在极端情况下，当启发函数h(n)始终为0，则将由g(n)决定节点的优先级，此时算法就退化成了Dijkstra算法。

如果h(n)始终小于等于节点n到终点的代价，则A*算法保证一定能够找到最短路径。但是当h(n)的值越小，算法将遍历越多的节点，也就导致算法越慢。

如果h(n)完全等于节点n到终点的代价，则A*算法将找到最佳路径，并且速度很快。可惜的是，并非所有场景下都能做到这一点。因为在没有达到终点之前，我们很难确切算出距离终点还有多远。

如果h(n)的值比节点n到终点的代价要大，则A*算法不能保证找到最短路径，不过此时会很快。

在另外一个极端情况下，如果h(n)相较于g(n)大很多，则此时只有h(n)产生效果，这也就变成了最佳优先搜索。

对于该题目，由于顶点间可以往任意方向出发，所以应该采用欧氏距离计算h(n)，关键部分代码如下：

```java
private void relax(EdgeWeightedDigraph G, int v) {
    for (DirectedEdge e : G.adj(v)) {
        int w = e.to();
        if (distToG[w] > distToG[v] + e.weight()) {
            distToG[w] = distToG[v] + e.weight();
            distToF[w] = distToG[w] + points[v].getDistance(points[w]);
            edgeTo[w] = e;

            if (pq.contains(w)) pq.changeKey(w, distToF[w]);
            else pq.insert(w, distToF[w]);
        }
        if (w == to) {
            while(!pq.isEmpty()) pq.delMin();
            break;
        }
    }
}
```

### 实验结果与分析

实验采用了迪杰斯特拉的堆优化加A*优化算法，可在亚线性时间内计算出结果。

如下，输入from（起点），to（终点），即可打印出路径和消耗路程长度。

```
from: 213
to: 4134
path: 213->209->196->203->202->201->178->159->124->123->119->100->115->132->135->134->90->53->59->68->70->72->74->82->99->101->103->113->114->116->118->126->130->129->127->136->139->133->122->102->97->96->87->84->78->80->55->51->40660->40649->40639->40638->40637->40636->40635->40626->40625->40624->40628->40627->40629->40623->40616->40599->71890->71879->71839->71822->71814->71763->71762->71755->71753->71725->71721->71717->71710->71703->71699->71698->71697->3257->3255->3256->3250->3248->3228->3226->3129->3127->3107->3077->3063->3061->3055->3034->3024->3021->3019->3005->2994->2976->2968->2967->2966->2965->2948->2947->2912->2911->2896->2886->2889->2874->2859->2847->2793->2792->2774->2772->2768->2740->2723->2679->2669->43728->43700->43679->43678->43674->43673->43672->43659->43640->43638->43625->43604->43560->43538->43540->43533->43524->43485->43480->43449->43443->43435->43421->43392->43406->43405->43402->43401->43398->43396->43397->43399->43419->43418->43432->43436->43445->43441->43423->28957->28956->28952->28949->28950->28946->28947->28955->28948->28951->28954->28953->28944->28943->28928->28808->28807->28790->28791->28761->28720->28735->28726->28723->28721->28725->28728->28727->28730->28731->28732->28729->28724->28722->28734->28733->28738->28741->28742->28745->28746->28758->28749->28751->28747->28750->28785->28777->28784->28782->28781->28780->28778->28783->28786->28806->28811->28815->28820->28819->28818->28667->28660->28659->28655->28652->28651->28648->28647->28632->28628->28588->28552->28551->28550->28547->28548->28537->28540->28530->28531->28562->28563->28546->28544->12633->12631->12628->12617->12618->12619->12620->12623->12611->12621->12624->12634->12648->12649->12647->12642->12643->12644->12645->12646->12641->12630->12625->12613->12606->12603->12584->12570->12564->12555->12557->12556->12545->12544->12543->12542->12537->12535->12531->12530->12523->12516->12513->12515->12514->12494->12524->12492->12486->12491->12490->12495->12521->12520->12487->12485->12497->12512->12525->12498->12499->12500->12502->12496->12480->12468->12453->12452->12451->12394->12339->12332->12331->12320->12309->12305->12303->12298->12295->12282->12280->12267->12257->12253->12258->79132->79145->79144->79135->79137->79147->79154->79161->79163->79146->79141->79142->79134->79124->79129->79130->79116->79119->79118->79120->45867->45866->45870->45839->45835->45838->45822->45823->45825->45824->45776->45747->45749->45787->45793->45820->45804->45786->45785->45813->45815->45833->45828->45830->45801->45802->45803->45796->45781->45740->45737->45736->45733->45731->45730->45732->45734->45772->45766->45760->45758->45756->45753->45750->45743->45738->45729->45726->4401->4396->4319->4317->4313->4318->4286->4265->4238->4239->4236->4226->4196->4197->4198->4199->4200->4174->4177->4171->4170->4159->4146->4141->4136->4134
consume: 7032.523933

from: 3442
to: 5513
path: 3442->3445->3444->3443->3390->3384->3385->3394->3398->3405->3438->3439->3434->3433->3436->3382->3372->3362->3359->3360->3366->3339->3296->3295->3294->3285->3277->3276->3272->3245->3244->3242->3240->3212->3191->3181->3185->3187->3216->3225->3183->3179->3174->3171->3175->3176->3168->3163->3162->3157->3156->3144->3141->3136->3135->3134->3130->61588->61515->61516->61518->61519->61513->61453->61455->61459->61458->61461->61465->61489->61510->61546->61545->61543->61542->61541->61551->61547->61561->61604->61605->61614->61609->61611->61610->61612->61613->61608->61589->61544->61531->61521->61512->61493->61492->61480->61478->61472->61473->61479->61487->61500->61506->61507->61504->61502->61505->61508->61501->61466->61433->61429->61426->61401->61393->61396->61387->61403->61397->61383->61384->61391->61406->61407->61427->61428->61432->61468->61565->61571->61572->61576->61577->61579->61607->61638->61653->61665->61690->61692->61693->72018->72021->72022->72024->72023->72079->72078->72083->72084->72082->72081->72077->72093->72052->72040->72038->72036->72037->72046->72054->72058->72059->72062->72061->72060->72056->72055->72066->72067->72072->72070->72069->72068->72041->72014->72000->72085->48106->48120->48173->48121->48125->48126->48122->48123->48124->48136->48144->48151->48157->48253->48307->48332->48338->48333->48325->48322->48318->48315->48317->48314->48306->48233->48219->48249->48291->48288->48283->48280->48273->48269->48267->48262->48257->48240->48231->48224->48222->48221->48228->48227->48226->48223->48198->48252->48259->48292->48294->48299->48321->48324->48303->48232->48166->48165->48139->48131->48107->48069->48059->48037->48027->48013->48014->48020->48021->48022->48023->48028->48030->1765->1777->1789->1804->1808->1816->1818->1819->1813->1814->1809->1807->1805->1780->1779->1772->1783->1785->1788->1784->1768->1774->1771->1766->1787->1799->1778->1775->1786->1781->1773->1792->1791->1782->46014->46013->46012->7558->7559->7708->7835->7843->7844->7836->7827->7828->7832->7823->7826->7824->7822->7800->7797->7796->7780->7775->7746->7747->7744->7734->7729->7707->7655->7647->7648->7646->7652->7651->7650->7649->7643->7642->7641->7645->7638->7640->7639->7637->7588->7506->7450->7426->7410->7405->7404->7403->7346->7331->7247->7038->6974->6921->6833->6817->6783->6391->6384->6342->6294->6151->6154->6150->6152->6153->6155->6157->6120->6122->6123->5897->5842->5733->5684->5670->5606->5604->5533->5527->5519->5506->5503->5489->5514->5518->5522->5539->5543->5512->5513
consume: 5932.895103

from: 23
to: 41234
path: 23->86->100->115->138->146->158->204->216->219->223->218->224->230->231->242->251->293->298->299->305->308->320->333->340->360->396->433->458->461->464->470->471->466->475->477->474->485->484->516->513->536->593->602->623->625->41048->41049->41050->41057->41059->41063->41077->41070->41075->41082->41083->41093->41095->41118->41122->41134->41169->41179->41180->41181->41182->41183->41191->41187->41178->41222->41229->41231->41242->41240->41239->41237->41236->41235->41234
consume: 941.642943
```